---
title: "GCP-GAIL - Quick Refresher"
description: "Last-minute cram session for Generative AI Leader exam"
---

# GCP-GAIL: Last-Minute Refresher

[â† Back to Overview](./index.md)

::: danger Final Review
This page is for the 15-minute "cram" session. Focus on the distinction between **Grounding** (accuracy) and **Tuning** (behavior).
:::

---

## ğŸ—ï¸ Domain 1: Vertex AI Foundation (~30%)

### The Gemini Family
- **Gemini Ultra**: Largest, most capable model for highly complex reasoning and coding.
- **Gemini Pro**: Best-of-breadth; optimized for scaling across a wide range of text and video tasks.
- **Gemini Flash**: Optimized for speed and efficiency; ideal for high-volume, low-latency tasks.
- **Gemini Nano**: Designed for on-device efficiency (Android/Pixel).

### Core Parameters
| Parameter | Effect | Use Case |
|-----------|--------|----------|
| **Temperature** | Controls randomness | High (0.8+) for creative writing; Low (0.1) for technical data. |
| **Top-K** | Limits vocabulary to K words | Prevents the model from picking highly unlikely "long tail" words. |
| **Top-P** | Dynamic vocabulary based on probability | Samples from the smallest set of words whose cumulative probability is P. |

---

## ğŸ¯ Decision Trees

### When to use RAG vs. Fine-Tuning?

```
Does the model need access to real-time or private data?
â”œâ”€ Yes, and data changes daily â†’ Use RAG (Vector Search + Grounding)
â”œâ”€ Yes, but data is static and specialized â†’ Use Fine-Tuning
â””â”€ No, I just need a specific output format â†’ Use Few-shot Prompting
```

### Choosing a Model Customization Path

```
What is the goal?
â”œâ”€ Optimize for cost/latency? â†’ Model Distillation
â”œâ”€ Adopt a specific "voice" or persona? â†’ Supervised Fine-Tuning (SFT)
â””â”€ Prevent specific types of hallucinations? â†’ Grounding with Google Search
```

---

## ğŸ›¡ï¸ Responsible AI & Safety

### Safety Filters
Vertex AI provides adjustable thresholds for:
- **Hate Speech**
- **Harassment**
- **Sexually Explicit**
- **Dangerous Content**

**Exam Tip:** If a model refuses to answer a valid query, check if the **Safety Filter** thresholds are set too "Strict."

---

## ğŸ”‘ Key Acronyms

| Acronym | Full Form | Quick Definition |
|---------|-----------|------------------|
| **RAG** | Retrieval-Augmented Generation | Attaching a "database" to the LLM to give it facts. |
| **CoT** | Chain of Thought | Telling the model to "Think step-by-step." |
| **SFT** | Supervised Fine-Tuning | Training a model on specific prompt-response pairs. |
| **RLHF** | Reinforcement Learning from Human Feedback | Training based on human "thumbs up/down" preferences. |

---

::: tip You've Got This!
Trust your knowledge of the Vertex AI workflow: **Discover** (Model Garden) â†’ **Experiment** (Studio) â†’ **Customize** (Tuning/RAG) â†’ **Deploy** (Endpoints). Good luck! ğŸ€
:::

[â† Back to Overview](./index.md) | [Study Notes](./notes.md) | [Exam Tips](./exam-tips.md)